{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6af3e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install SpeechRecognition\n",
    "#pip install pyaudio\n",
    "#pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c7bd916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "    import speech_recognition as sr\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "\n",
    "        r.energy_threshold = 300\n",
    "        r.dynamic_energy_threshold = True\n",
    "        r.dynamic_energy_adjustment_ratio = 1.5\n",
    "        r.pause_threshold = 0.5\n",
    "        r.non_speaking_duration = 0.3\n",
    "        r.operation_timeout = None\n",
    "        r.phrase_threshold = 0.3\n",
    "        r.max_silence = 1\n",
    "        r.adjust_for_ambient_noise(source, duration=0.5)\n",
    "\n",
    "        print(\"Speak...\")\n",
    "    \n",
    "        try:\n",
    "            audio = r.listen(source, phrase_time_limit=5)\n",
    "    \n",
    "            text = r.recognize_google(audio,language=  \"EN_US\")\n",
    "\n",
    "            print(\"You said: \" + text)\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "\n",
    "            print(\"Could not understand audio\")\n",
    "\n",
    "        except sr.RequestError as e:\n",
    "\n",
    "            print(\"Error: {0}\".format(e))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e59aacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak...\n",
      "You said: I am feeling great suggest me a playlist\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('vader_lexicon')\n",
    "#nltk.download('punkt')\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "output = get_text()\n",
    "word_tokenize(output)\n",
    "scores = sid.polarity_scores(output)\n",
    "if scores['compound'] >= 0.2 and scores['compound']<0.8:\n",
    "    print(\"happy\")\n",
    "elif scores['compound'] <= -0.2 and scores['compound']>-0.75:\n",
    "    print(\"sad\")\n",
    "elif scores['compound'] > -0.2 and scores['compound'] < 0.2:\n",
    "    print(\"normal\")\n",
    "elif scores['compound'] <=-0.75:\n",
    "    print(\"angry\")\n",
    "else:\n",
    "    print(\"excited\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b62b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
